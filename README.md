In our project, we focus on training and evaluating different models to see how well they perform in identifying human values in textual data. Inspired by the objectives of SemEval Task 4, our goal is to compare the effectiveness of these models in recognizing specific value categories within text. Each model undergoes training on annotated data and is then assessed based on its ability to predict the presence or absence of values in given textual arguments. Through this comparative approach, we aim to gain insights into the strengths and weaknesses of different model architectures and techniques in addressing this task.
